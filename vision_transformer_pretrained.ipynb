{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(image):\n",
    "    if not isinstance(image, Image.Image):\n",
    "        image = Image.fromarray(image)\n",
    "    return feature_extractor(images=image, return_tensors='pt').pixel_values.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ImageFolder(root='train', transform=transform)\n",
    "val_data = ImageFolder(root='validation', transform=transform)\n",
    "test_data = ImageFolder(root='test', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224', num_labels=2, ignore_mismatched_sizes=True  )\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10, patience=3, save_best_model=False, verbose=True):\n",
    "    model.to(device)\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "        total_train_loss = 0\n",
    "        total_train_correct = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Training loop\n",
    "        for inputs, labels in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs} [Training]', unit='batch'):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs).logits  # For ViT, use logits attribute\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            total_train_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        total_val_loss = 0\n",
    "        total_val_correct = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(val_loader, desc=f'Epoch {epoch + 1}/{num_epochs} [Validation]', unit='batch'):\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs).logits  # For ViT, use logits attribute\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                total_val_loss += loss.item()\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                total_val_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        # Calculate average losses and accuracy\n",
    "        avg_train_loss = total_train_loss / len(train_loader.dataset)\n",
    "        avg_val_loss = total_val_loss / len(val_loader.dataset)\n",
    "        train_acc = total_train_correct.double() / len(train_loader.dataset)\n",
    "        val_acc = total_val_correct.double() / len(val_loader.dataset)\n",
    "        epoch_duration = time.time() - start_time\n",
    "\n",
    "        # Print training/validation statistics\n",
    "        if verbose:\n",
    "            print(f'Epoch {epoch + 1}/{num_epochs}, Duration: {epoch_duration:.2f}s, Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "        # Early stopping and saving the best model\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_model_state = model.state_dict()\n",
    "            if save_best_model:\n",
    "                torch.save(model.state_dict(), 'best_model_vit.pth')\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve == patience:\n",
    "                if verbose:\n",
    "                    print(f'Early stopping triggered after {epoch + 1} epochs!')\n",
    "                model.load_state_dict(best_model_state)\n",
    "                break\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10, patience=3, save_best_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'final_model_vit.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, roc_curve\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    'google/vit-base-patch16-224', \n",
    "    num_labels=2,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "model.load_state_dict(torch.load('final_model_vit.pth'))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "scores = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, batch_labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "\n",
    "        outputs = model(inputs).logits\n",
    "        probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "\n",
    "        labels.extend(batch_labels.cpu().numpy())\n",
    "        scores.extend(probabilities.cpu().numpy())\n",
    "\n",
    "# Convert scores and labels to numpy arrays for metric calculations\n",
    "labels = np.array(labels)\n",
    "scores = np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(labels, scores, far_target=1e-3):\n",
    "    labels = np.array(labels)\n",
    "    scores = np.array(scores)[:, 1]  # Take the probabilities of the positive class\n",
    "\n",
    "    # Accuracy\n",
    "    predictions = (scores > 0.5).astype(int) \n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "\n",
    "    # Calculate ROC Curve and EER\n",
    "    fpr, tpr, thresholds = roc_curve(labels, scores)\n",
    "    eer = brentq(lambda x: 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n",
    "\n",
    "    # Find TAR at specified FAR\n",
    "    far_index = np.where(fpr <= far_target)[0][-1]\n",
    "    tar_at_far = tpr[far_index]\n",
    "\n",
    "    return accuracy, eer, tar_at_far\n",
    "\n",
    "# Calculate the metrics\n",
    "accuracy, eer, tar_at_far = calculate_metrics(labels, scores)\n",
    "far_target = 1e-3\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'EER: {eer:.4f}')\n",
    "print(f'TAR at FAR={far_target}: {tar_at_far:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
