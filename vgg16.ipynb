{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3795,"status":"ok","timestamp":1702795936062,"user":{"displayName":"Maida A","userId":"15235040500997925949"},"user_tz":-540},"id":"ruQArIsHWrGI","outputId":"f18cab7b-45bd-42a4-b42a-23c103e2bbee"},"outputs":[],"source":["# Imports\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":374,"status":"ok","timestamp":1702809812087,"user":{"displayName":"Maida A","userId":"15235040500997925949"},"user_tz":-540},"id":"79-iDvxRaDVF"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader, WeightedRandomSampler\n","from torchvision.datasets import ImageFolder\n","\n","import numpy as np\n","from sklearn.metrics import roc_curve, accuracy_score, precision_recall_curve, f1_score\n","from scipy.optimize import brentq\n","from scipy.interpolate import interp1d\n","\n","from tqdm import tqdm\n","import time\n","\n","import matplotlib.pyplot as plt\n","import os\n","\n","# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1025,"status":"ok","timestamp":1702803122539,"user":{"displayName":"Maida A","userId":"15235040500997925949"},"user_tz":-540},"id":"pwWRqWPAabWh"},"outputs":[],"source":["# Transforms\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1702803122539,"user":{"displayName":"Maida A","userId":"15235040500997925949"},"user_tz":-540},"id":"I7qVrU8Qahee"},"outputs":[],"source":["train_data = ImageFolder(root='/content/drive/My Drive/KAIST/CS470/Project_2/splitted/train', transform=transform)\n","val_data = ImageFolder(root='/content/drive/My Drive/KAIST/CS470/Project_2/splitted/validation', transform=transform)\n","test_data = ImageFolder(root='/content/drive/My Drive/KAIST/CS470/Project_2/splitted/test', transform=transform)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1702803123558,"user":{"displayName":"Maida A","userId":"15235040500997925949"},"user_tz":-540},"id":"-3RSEfIdHaGF"},"outputs":[],"source":["# Creating data loaders\n","train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n","val_loader = DataLoader(val_data, batch_size=64, shuffle=False)\n","test_loader = DataLoader(test_data, batch_size=64, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2105,"status":"ok","timestamp":1702803128126,"user":{"displayName":"Maida A","userId":"15235040500997925949"},"user_tz":-540},"id":"VAvqNybjt94k"},"outputs":[],"source":["class VGG16(nn.Module):\n","    def __init__(self, num_classes=2):\n","        super(VGG16, self).__init__()\n","        # Convolutional layers\n","        self.conv_layers = nn.Sequential(\n","            # Block 1\n","            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            # Block 2\n","            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            # Block 3\n","            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            # Block 4\n","            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            # Block 5\n","            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2)\n","        )\n","\n","        # Fully connected layers\n","        self.fc_layers = nn.Sequential(\n","            nn.Linear(512 * 7 * 7, 4096),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(4096, 4096),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(4096, num_classes),\n","            #nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        # Pass the input through the convolutional layers\n","        x = self.conv_layers(x)\n","\n","        # Flatten the output for the fully connected layers\n","        x = x.view(x.size(0), -1)\n","\n","        # Pass the input through the fully connected layers\n","        x = self.fc_layers(x)\n","        #print(x.shape)\n","        return x\n","\n","# Create the VGG16 model\n","model = VGG16().to(device)\n","\n","class_weights = [1.0 / count for count in [1372, 5797]]\n","class_weights = torch.FloatTensor(class_weights).to(device)\n","\n","# criterion = nn.BCELoss()\n","criterion = nn.CrossEntropyLoss(weight=class_weights)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":838166,"status":"ok","timestamp":1702803977877,"user":{"displayName":"Maida A","userId":"15235040500997925949"},"user_tz":-540},"id":"WZ4vhXbV3WYY","outputId":"92521353-a81e-4bb8-9d58-a25393755378"},"outputs":[],"source":["# Early stopping parameters\n","patience = 5\n","best_val_loss = float('inf')\n","epochs_no_improve = 0\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2)\n","\n","# Training loop\n","num_epochs = 10\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    total_train_loss = 0\n","    total_train_correct = 0\n","\n","    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"):\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        outputs = model(inputs)\n","        # print(outputs.shape)\n","        # print(labels.shape)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_train_loss += loss.item()\n","        _, predicted = torch.max(outputs.data, 1)\n","        total_train_correct += (predicted == labels).sum().item()\n","\n","    # Calculate training loss and accuracy\n","    avg_train_loss = total_train_loss / len(train_loader.dataset)\n","    train_accuracy = total_train_correct / len(train_loader.dataset)\n","\n","    # Validation loop\n","    model.eval()\n","    total_val_loss = 0\n","    total_val_correct = 0\n","\n","    with torch.no_grad():\n","        for inputs, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\"):\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","\n","            total_val_loss += loss.item()\n","            _, predicted = torch.max(outputs.data, 1)\n","            total_val_correct += (predicted == labels).sum().item()\n","\n","    # Calculate validation loss and accuracy\n","    avg_val_loss = total_val_loss / len(val_loader.dataset)\n","    val_accuracy = total_val_correct / len(val_loader.dataset)\n","    scheduler.step(avg_val_loss)\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        epochs_no_improve = 0\n","        # Save the best model if required\n","        torch.save(model.state_dict(), '/content/drive/My Drive/KAIST/CS470/Project_2/best_model_vgg16_final.pth')\n","\n","    else:\n","        epochs_no_improve += 1\n","        if epochs_no_improve == patience:\n","            print(f'Early stopping triggered after {epoch + 1} epochs')\n","            break  # Early stopping\n","\n","    print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Train Acc: {train_accuracy:.4f}, Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.4f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10690,"status":"ok","timestamp":1702803989746,"user":{"displayName":"Maida A","userId":"15235040500997925949"},"user_tz":-540},"id":"Mek2D3Az2wsP","outputId":"5a42900f-6a2d-41ba-af9d-16c389e97977"},"outputs":[],"source":["# Accuracy, EER, and TAR at specific FAR\n","def calculate_metrics(labels, scores, far_target=1e-3):\n","    labels = np.array(labels)\n","    scores = np.array(scores)  # Keep it as 1D if your model only outputs one probability per example\n","    fpr, tpr, thresholds = roc_curve(labels, scores)\n","    eer = brentq(lambda x: 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n","    far_index = np.where(fpr <= far_target)[0][-1]\n","    tar_at_far = tpr[far_index]\n","    accuracy = accuracy_score(labels, scores > 0.5)  # Directly use scores as 1D array\n","    return accuracy, eer, tar_at_far\n","\n","# Testing Loop\n","model.eval()\n","all_labels = []\n","all_scores = []\n","\n","with torch.no_grad():\n","    for inputs, labels in tqdm(test_loader, desc=\"Testing\"):\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        outputs = model(inputs)\n","        #print(\"Raw model outputs:\", outputs)\n","        #break  # Remove break to see more batches\n","\n","        # Convert logits to probabilities using softmax for CrossEntropyLoss\n","        probabilities = torch.softmax(outputs, dim=1)[:, 1]  # Probabilities for the positive class\n","        all_scores.extend(probabilities.cpu().numpy())\n","        all_labels.extend(labels.cpu().numpy())\n","\n","# Calculate and print metrics\n","accuracy, eer, tar_at_far = calculate_metrics(all_labels, all_scores)\n","print(f'Accuracy: {accuracy:.4f}, EER: {eer:.4f}, TAR at FAR={1e-3}: {tar_at_far:.4f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":513,"status":"ok","timestamp":1702798154755,"user":{"displayName":"Maida A","userId":"15235040500997925949"},"user_tz":-540},"id":"ZW_rpg8grdEi","outputId":"a46526b7-65f8-4e89-9f36-04ff345ab216"},"outputs":[],"source":["# Calculate and print metrics\n","accuracy, eer, tar_at_far = calculate_metrics(all_labels, all_scores)\n","print(f'Accuracy: {accuracy:.4f}, EER: {eer:.4f}, TAR at FAR={1e-3}: {tar_at_far:.4f}')"]},{"cell_type":"markdown","metadata":{"id":"81wriLnq0ULI"},"source":["Just some debugging stuff here"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11245,"status":"ok","timestamp":1702802637597,"user":{"displayName":"Maida A","userId":"15235040500997925949"},"user_tz":-540},"id":"KKaWVeOlw5IW","outputId":"eb1c303e-2c4b-45dd-d15a-3319960638c1"},"outputs":[],"source":["from pathlib import Path\n","\n","def evaluate_model(test_loader, model, device):\n","    model.eval()\n","    correct_forged = 0\n","    correct_genuine = 0\n","    total_forged = 0\n","    total_genuine = 0\n","\n","    with torch.no_grad():\n","        for inputs, labels, paths in test_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","            _, preds = torch.max(outputs, 1)\n","\n","            for path, label, pred in zip(paths, labels, preds):\n","                category = Path(path).parent.name\n","                if category == 'negative':\n","                    total_forged += 1\n","                    correct_forged += (pred == label).item()\n","                elif category == 'positive':\n","                    total_genuine += 1\n","                    correct_genuine += (pred == label).item()\n","\n","    forged_accuracy = correct_forged / total_forged if total_forged > 0 else 1\n","    genuine_accuracy = correct_genuine / total_genuine if total_genuine > 0 else 1\n","\n","    return forged_accuracy, genuine_accuracy\n","\n","# Modify the DataLoader to return file paths\n","class ImageFolderWithPaths(datasets.ImageFolder):\n","    def __getitem__(self, index):\n","        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n","        path = self.imgs[index][0]\n","        return (original_tuple + (path,))\n","\n","test_data_with_paths = ImageFolderWithPaths('/content/drive/My Drive/KAIST/CS470/Project_2/splitted/test', transform=transform)\n","test_loader_with_paths = DataLoader(test_data_with_paths, batch_size=64, shuffle=False)\n","\n","# Evaluate the model\n","forged_accuracy, genuine_accuracy = evaluate_model(test_loader_with_paths, model, device)\n","print(f'Forged Accuracy: {forged_accuracy*100:.2f}%')\n","print(f'Genuine Accuracy: {genuine_accuracy*100:.2f}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N5X_ctL1xiTM"},"outputs":[],"source":["def debug_predictions(test_loader, model, device, num_samples=500):\n","    model.eval()\n","    samples_checked = 0\n","\n","    with torch.no_grad():\n","        for inputs, labels, paths in test_loader:\n","            if samples_checked >= num_samples:\n","                break\n","\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","            _, preds = torch.max(outputs, 1)\n","\n","            for path, label, pred in zip(paths, labels, preds):\n","                if samples_checked >= num_samples:\n","                    break\n","                print(f'Path: {path}, Actual: {label.item()}, Predicted: {pred.item()}')\n","                samples_checked += 1\n","\n","debug_predictions(test_loader_with_paths, model, device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34926,"status":"ok","timestamp":1702802684832,"user":{"displayName":"Maida A","userId":"15235040500997925949"},"user_tz":-540},"id":"WiLbugDN0ajY","outputId":"3742960b-e064-4e98-e5c4-4db2280b3cc8"},"outputs":[],"source":["class_counts = {}\n","for _, label in train_data:\n","    if label in class_counts:\n","        class_counts[label] += 1\n","    else:\n","        class_counts[label] = 1\n","\n","print(\"Class counts:\", class_counts)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8443,"status":"ok","timestamp":1702803090062,"user":{"displayName":"Maida A","userId":"15235040500997925949"},"user_tz":-540},"id":"GMw5-IuL-PUc","outputId":"707517f0-b1f9-4b6d-e719-a1811fed84f6"},"outputs":[],"source":["class_counts = {}\n","for _, label in test_data:\n","    if label in class_counts:\n","        class_counts[label] += 1\n","    else:\n","        class_counts[label] = 1\n","\n","print(\"Class counts:\", class_counts)"]},{"cell_type":"markdown","metadata":{"id":"FccZEbi2ChqN"},"source":["Analysis"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":7071,"status":"ok","timestamp":1702809524846,"user":{"displayName":"Maida A","userId":"15235040500997925949"},"user_tz":-540},"id":"t4p0ldT7Cj5I","outputId":"ea3bcedd-bf83-46aa-8262-5275c4514aad"},"outputs":[],"source":["def visualize_misclassified_samples_with_filenames(data_loader, model, num_images=10, title='Misclassified Samples'):\n","    model.eval()\n","    images, predictions, true_labels, filenames = [], [], [], []\n","    misclassified_filenames = []  # Keep track of misclassified filenames\n","    with torch.no_grad():\n","        for inputs, labels in data_loader:\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","            outputs = model(inputs)\n","            _, preds = torch.max(outputs, 1)\n","\n","            for input, pred, true, path in zip(inputs, preds, labels, data_loader.dataset.samples):\n","                if pred != true:\n","                    images.append(input.cpu().data)\n","                    predictions.append(pred.item())\n","                    true_labels.append(true.item())\n","                    filenames.append(os.path.basename(path[0]))  # Extract filename from path\n","                    misclassified_filenames.append(os.path.basename(path[0]))  # Track misclassified filenames\n","                    if len(images) == num_images:\n","                        break\n","            if len(images) == num_images:\n","                break\n","\n","    # Plotting\n","    fig, axes = plt.subplots(2, num_images // 2, figsize=(15, 5))\n","    fig.suptitle(title)\n","    axes = axes.flatten()\n","    for i, (img, pred, true, fname) in enumerate(zip(images, predictions, true_labels, filenames)):\n","        img = img.numpy().transpose((1, 2, 0))\n","        axes[i].imshow(img)\n","        axes[i].axis('off')\n","        axes[i].set_title(f'File: {fname}\\nPred: {pred}, True: {true}')\n","    plt.tight_layout()\n","    plt.show()\n","\n","# Call the function to visualize misclassified samples with filenames\n","pretrained_model = VGG16().to(device)\n","pretrained_model.load_state_dict(torch.load('/content/drive/My Drive/KAIST/CS470/Project_2/best_model_vgg16.pth'))\n","pretrained_model.eval()\n","\n","# Call the function to visualize misclassified samples with filenames\n","visualize_misclassified_samples_with_filenames(test_loader, pretrained_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21204,"status":"ok","timestamp":1702809576986,"user":{"displayName":"Maida A","userId":"15235040500997925949"},"user_tz":-540},"id":"BxVJ-z_hWqoH","outputId":"18d89be5-7005-47f4-dae1-757359699987"},"outputs":[],"source":["def list_misclassified_filenames(data_loader, model):\n","    model.eval()\n","    misclassified_filenames = []\n","    with torch.no_grad():\n","        for inputs, labels in data_loader:\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","            outputs = model(inputs)\n","            _, preds = torch.max(outputs, 1)\n","\n","            for pred, true, path in zip(preds, labels, data_loader.dataset.samples):\n","                if pred != true:\n","                    filename = os.path.basename(path[0])  # Extract filename from path\n","                    misclassified_filenames.append(filename)\n","\n","    return misclassified_filenames\n","\n","# Get the list of misclassified filenames\n","misclassified_filenames = list_misclassified_filenames(test_loader, model)\n","\n","print(len(misclassified_filenames))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":507,"status":"ok","timestamp":1702809658880,"user":{"displayName":"Maida A","userId":"15235040500997925949"},"user_tz":-540},"id":"NcxnSdelXQjY","outputId":"1cc5960c-ce5d-4b55-dcfb-67756755f273"},"outputs":[],"source":["count = 0\n","for filename in misclassified_filenames:\n","    # Split the filename using '-' as a delimiter\n","    parts = filename.split('-')\n","\n","    # Extract the first part of the split (i.e., the number) and convert it to an integer\n","    first_number = int(parts[1])\n","\n","    # Check if the first number is greater than 100\n","    if first_number > 100:\n","        count += 1\n","\n","print(\"Professional Signatures:\", count)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOgW7T1dfcjJtlc+xzhVE+s","gpuType":"V100","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
