{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNeXT 50 architecture implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CardinalityBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, identity_downsample=None, stride=1, C=32):\n",
    "        super(CardinalityBlock, self).__init__()\n",
    "        self.expansion = 2\n",
    "        self.C = C\n",
    "        self.small_out_channels = out_channels // C\n",
    "        self.branch = self._make_branch(in_channels, stride)\n",
    "        self.identity_downsample = identity_downsample\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def _make_branch(self, in_channels, stride):\n",
    "        branch_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, self.small_out_channels, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(self.small_out_channels),\n",
    "            nn.Conv2d(self.small_out_channels, self.small_out_channels, kernel_size=3, stride=stride, padding=1),\n",
    "            nn.BatchNorm2d(self.small_out_channels),\n",
    "            nn.Conv2d(self.small_out_channels, self.small_out_channels * self.expansion, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(self.small_out_channels * self.expansion)\n",
    "        )\n",
    "        return branch_layers\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        branches = [self.branch(x) for _ in range(self.C)]\n",
    "        x = torch.cat(branches, 1)\n",
    "\n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNeXt(nn.Module):\n",
    "    def __init__(self, cardinalityBlock, num_repeat, image_channels, num_classes):\n",
    "        super(ResNeXt, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.initial_layers = self._init_layers(image_channels)\n",
    "        self.conv2, self.conv3, self.conv4, self.conv5 = self._make_layers(cardinalityBlock, num_repeat)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(1024 * 2, num_classes)\n",
    "\n",
    "    def _init_layers(self, image_channels):\n",
    "        layers = nn.Sequential(\n",
    "            nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        return layers\n",
    "\n",
    "    def _make_layers(self, block, num_repeat):\n",
    "        layers = []\n",
    "        out_channels_list = [128, 256, 512, 1024]\n",
    "        for idx, num_blocks in enumerate(num_repeat):\n",
    "            stride = 1 if idx == 0 else 2\n",
    "            layer = self._create_resBlock(block, num_blocks, out_channels_list[idx], stride)\n",
    "            layers.append(layer)\n",
    "        return layers\n",
    "\n",
    "    def _create_resBlock(self, block, num_blocks, out_channels, stride):\n",
    "        identity_downsample = None\n",
    "        if self.in_channels != out_channels * 2:\n",
    "            identity_downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, out_channels * 2, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels * 2)\n",
    "            )\n",
    "        layers = [block(self.in_channels, out_channels, identity_downsample, stride)]\n",
    "        self.in_channels = out_channels * 2\n",
    "        layers.extend([block(self.in_channels, out_channels) for _ in range(num_blocks - 1)])\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.initial_layers(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNeXt50(image_channels=3, num_classes=1000):\n",
    "    return ResNeXt(CardinalityBlock, [3, 4, 6, 3], image_channels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to the input size of the model\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Loading datasets\n",
    "train_data = ImageFolder(root='train', transform=transform)\n",
    "val_data = ImageFolder(root='validation', transform=transform)\n",
    "test_data = ImageFolder(root='test', transform=transform)\n",
    "\n",
    "# Creating data loaders\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Initialize the model\n",
    "model = ResNeXt50()\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 2)  # Adjust the number of output classes\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "\n",
    "# def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10, patience=3):\n",
    "#     model.to(device)\n",
    "#     best_val_loss = float('inf')\n",
    "#     epochs_no_improve = 0\n",
    "#     best_model_state = None\n",
    "\n",
    "#     for epoch in range(num_epochs):\n",
    "#         model.train()\n",
    "#         total_train_loss = 0\n",
    "\n",
    "#         # Training loop with progress bar\n",
    "#         train_progress_bar = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs} [Training]', unit='batch')\n",
    "#         for inputs, labels in train_progress_bar:\n",
    "#             inputs, labels = inputs.to(device), labels.to(device)\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(inputs)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             total_train_loss += loss.item()\n",
    "\n",
    "#         # Validation loop with progress bar\n",
    "#         model.eval()\n",
    "#         total_val_loss = 0\n",
    "#         val_progress_bar = tqdm(val_loader, desc=f'Epoch {epoch + 1}/{num_epochs} [Validation]', unit='batch')\n",
    "#         with torch.no_grad():\n",
    "#             for inputs, labels in val_progress_bar:\n",
    "#                 inputs, labels = inputs.to(device), labels.to(device)\n",
    "#                 outputs = model(inputs)\n",
    "#                 loss = criterion(outputs, labels)\n",
    "#                 total_val_loss += loss.item()\n",
    "\n",
    "#         avg_train_loss = total_train_loss / len(train_loader)\n",
    "#         avg_val_loss = total_val_loss / len(val_loader)\n",
    "\n",
    "#         print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n",
    "\n",
    "#         # Early stopping logic\n",
    "#         if avg_val_loss < best_val_loss:\n",
    "#             best_val_loss = avg_val_loss\n",
    "#             best_model_state = model.state_dict()\n",
    "#             epochs_no_improve = 0\n",
    "#         else:\n",
    "#             epochs_no_improve += 1\n",
    "#             if epochs_no_improve == patience:\n",
    "#                 print(f'Early stopping triggered after {epoch + 1} epochs!')\n",
    "#                 model.load_state_dict(best_model_state)\n",
    "#                 break\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Training Function\n",
    "import time\n",
    "import torch\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10, patience=3, save_best_model=False, verbose=True):\n",
    "    model.to(device)\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    best_model_state = None\n",
    "    # scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.01) \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        total_train_correct = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Training loop with progress bar\n",
    "        train_progress_bar = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs} [Training]', unit='batch')\n",
    "        for inputs, labels in train_progress_bar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            total_train_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        # scheduler.step()  # Update learning rate\n",
    "\n",
    "        # Validation loop with progress bar\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        total_val_correct = 0\n",
    "        with torch.no_grad():\n",
    "            val_progress_bar = tqdm(val_loader, desc=f'Epoch {epoch + 1}/{num_epochs} [Validation]', unit='batch')\n",
    "            for inputs, labels in val_progress_bar:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                total_val_loss += loss.item()\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                total_val_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader.dataset)\n",
    "        avg_val_loss = total_val_loss / len(val_loader.dataset)\n",
    "        train_acc = total_train_correct.double() / len(train_loader.dataset)\n",
    "        val_acc = total_val_correct.double() / len(val_loader.dataset)\n",
    "        epoch_duration = time.time() - start_time\n",
    "\n",
    "        if verbose:\n",
    "            print(f'Epoch {epoch + 1}/{num_epochs}, Duration: {epoch_duration:.2f}s, Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "        # Early stopping and saving best model\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_model_state = model.state_dict()\n",
    "            if save_best_model:\n",
    "                torch.save(model.state_dict(), 'best_model.pth')\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve == patience:\n",
    "                if verbose:\n",
    "                    print(f'Early stopping triggered after {epoch + 1} epochs!')\n",
    "                model.load_state_dict(best_model_state)\n",
    "                break\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20  # Adjust the number of epochs as needed\n",
    "patience = 5     # Adjust the patience for early stopping\n",
    "save_best_model = True  # Set to True if you want to save the best model\n",
    "\n",
    "# Call the updated train_model function with all required arguments\n",
    "trained_model = train_model(\n",
    "    model, \n",
    "    train_loader, \n",
    "    val_loader, \n",
    "    criterion, \n",
    "    optimizer, \n",
    "    num_epochs=num_epochs, \n",
    "    patience=patience, \n",
    "    save_best_model=save_best_model,\n",
    "    verbose=True  \n",
    ")\n",
    "\n",
    "# Optionally, you can save the final trained model state as well\n",
    "model_save_path = 'final_trained_model.pth'\n",
    "torch.save(trained_model.state_dict(), model_save_path)\n",
    "print(f'Final trained model state dictionary saved to {model_save_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FINAL TRAINED MODEL TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Load the model architecture\n",
    "model = ResNeXt50()\n",
    "model_save_path = 'final_trained_model.pth'  # Replace with your model's path\n",
    "model.fc = nn.Linear(num_features, 2)\n",
    "\n",
    "# Load the saved state dictionary\n",
    "model.load_state_dict(torch.load(model_save_path, map_location=device))\n",
    "\n",
    "# Move model to the right device and set to evaluation mode\n",
    "model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, target_labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # If your model outputs logits, convert them to probabilities using sigmoid or softmax (as appropriate)\n",
    "        probabilities = torch.sigmoid(outputs).cpu().numpy()\n",
    "        scores.extend(probabilities)\n",
    "        labels.extend(target_labels.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, roc_curve\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(labels, scores, far_target=1e-3):\n",
    "    labels = np.array(labels)\n",
    "    scores = np.array(scores)[:, 1]  # Take the probabilities of the positive class\n",
    "\n",
    "    # Accuracy\n",
    "    predictions = (scores > 0.5).astype(int)  # Using 0.5 as the threshold\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "\n",
    "    # Calculate ROC Curve and EER\n",
    "    fpr, tpr, thresholds = roc_curve(labels, scores)\n",
    "    eer = brentq(lambda x: 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n",
    "\n",
    "    # Find TAR at specified FAR\n",
    "    far_index = np.where(fpr <= far_target)[0][-1]\n",
    "    tar_at_far = tpr[far_index]\n",
    "\n",
    "    return accuracy, eer, tar_at_far\n",
    "\n",
    "# Calculate the metrics\n",
    "accuracy, eer, tar_at_far = calculate_metrics(labels, scores)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'EER: {eer:.4f}')\n",
    "print(f'TAR at FAR={1e-3}: {tar_at_far:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def visualize_misclassified_samples_with_filenames(data_loader, model, num_images=10, title='Misclassified Samples'):\n",
    "    model.eval()\n",
    "    images, predictions, true_labels, filenames = [], [], [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for input, pred, true, path in zip(inputs, preds, labels, data_loader.dataset.samples):\n",
    "                if pred != true:\n",
    "                    images.append(input.cpu().data)\n",
    "                    predictions.append(pred.item())\n",
    "                    true_labels.append(true.item())\n",
    "                    filenames.append(os.path.basename(path[0]))  # Extract filename from path\n",
    "                    if len(images) == num_images:\n",
    "                        break\n",
    "            if len(images) == num_images:\n",
    "                break\n",
    "\n",
    "    # Plotting\n",
    "    fig, axes = plt.subplots(2, num_images // 2, figsize=(15, 5))\n",
    "    fig.suptitle(title)\n",
    "    axes = axes.flatten()\n",
    "    for i, (img, pred, true, fname) in enumerate(zip(images, predictions, true_labels, filenames)):\n",
    "        img = img.numpy().transpose((1, 2, 0))\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title(f'File: {fname}\\nPred: {pred}, True: {true}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to visualize misclassified samples with filenames\n",
    "visualize_misclassified_samples_with_filenames(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def list_misclassified_filenames(data_loader, model):\n",
    "    model.eval()\n",
    "    misclassified_filenames = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for pred, true, path in zip(preds, labels, data_loader.dataset.samples):\n",
    "                if pred != true:\n",
    "                    filename = os.path.basename(path[0])  # Extract filename from path\n",
    "                    misclassified_filenames.append(filename)\n",
    "\n",
    "    return misclassified_filenames\n",
    "\n",
    "# Get the list of misclassified filenames\n",
    "misclassified_filenames = list_misclassified_filenames(test_loader, model)\n",
    "\n",
    "# Optionally, print the list\n",
    "for filename in misclassified_filenames:\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(misclassified_filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for filename in misclassified_filenames:\n",
    "    # Split the filename using '-' as a delimiter\n",
    "    parts = filename.split('-')\n",
    "    \n",
    "    # Extract the first part of the split (i.e., the number) and convert it to an integer\n",
    "    first_number = int(parts[1])\n",
    "    \n",
    "    # Check if the first number is greater than 100\n",
    "    if first_number > 100:\n",
    "        count += 1\n",
    "\n",
    "print(\"Professional Signatures:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = r'C:\\Mine\\Work\\Uzi\\Signature_Verification\\test\\positive'\n",
    "\n",
    "# Get the list of files in the folder\n",
    "folder_files = os.listdir(folder_path)\n",
    "count = 0\n",
    "\n",
    "# Iterate through the misclassified filenames and check if they exist in the folder\n",
    "for filename in misclassified_filenames:\n",
    "    if filename in folder_files:\n",
    "        count += 1\n",
    "\n",
    "print(\"Number of misclassified Originals:\", count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Model Trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Load the model architecture\n",
    "model = ResNeXt50()\n",
    "model_save_path = 'best_model.pth'  # Replace with your model's path\n",
    "model.fc = nn.Linear(num_features, 2)\n",
    "\n",
    "# Load the saved state dictionary\n",
    "model.load_state_dict(torch.load(model_save_path, map_location=device))\n",
    "\n",
    "# Move model to the right device and set to evaluation mode\n",
    "model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, target_labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # If your model outputs logits, convert them to probabilities using sigmoid or softmax (as appropriate)\n",
    "        probabilities = torch.sigmoid(outputs).cpu().numpy()\n",
    "        scores.extend(probabilities)\n",
    "        labels.extend(target_labels.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, roc_curve\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(labels, scores, far_target=1e-3):\n",
    "    labels = np.array(labels)\n",
    "    scores = np.array(scores)[:, 1]  # Take the probabilities of the positive class\n",
    "\n",
    "    # Accuracy\n",
    "    predictions = (scores > 0.5).astype(int)  # Using 0.5 as the threshold\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "\n",
    "    # Calculate ROC Curve and EER\n",
    "    fpr, tpr, thresholds = roc_curve(labels, scores)\n",
    "    eer = brentq(lambda x: 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n",
    "\n",
    "    # Find TAR at specified FAR\n",
    "    far_index = np.where(fpr <= far_target)[0][-1]\n",
    "    tar_at_far = tpr[far_index]\n",
    "\n",
    "    return accuracy, eer, tar_at_far\n",
    "\n",
    "# Calculate the metrics\n",
    "accuracy, eer, tar_at_far = calculate_metrics(labels, scores)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'EER: {eer:.4f}')\n",
    "print(f'TAR at FAR={1e-3}: {tar_at_far:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def visualize_misclassified_samples_with_filenames(data_loader, model, num_images=10, title='Misclassified Samples'):\n",
    "    model.eval()\n",
    "    images, predictions, true_labels, filenames = [], [], [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for input, pred, true, path in zip(inputs, preds, labels, data_loader.dataset.samples):\n",
    "                if pred != true:\n",
    "                    images.append(input.cpu().data)\n",
    "                    predictions.append(pred.item())\n",
    "                    true_labels.append(true.item())\n",
    "                    filenames.append(os.path.basename(path[0]))  # Extract filename from path\n",
    "                    if len(images) == num_images:\n",
    "                        break\n",
    "            if len(images) == num_images:\n",
    "                break\n",
    "\n",
    "    # Plotting\n",
    "    fig, axes = plt.subplots(2, num_images // 2, figsize=(15, 5))\n",
    "    fig.suptitle(title)\n",
    "    axes = axes.flatten()\n",
    "    for i, (img, pred, true, fname) in enumerate(zip(images, predictions, true_labels, filenames)):\n",
    "        img = img.numpy().transpose((1, 2, 0))\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title(f'File: {fname}\\nPred: {pred}, True: {true}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to visualize misclassified samples with filenames\n",
    "visualize_misclassified_samples_with_filenames(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def list_misclassified_filenames(data_loader, model):\n",
    "    model.eval()\n",
    "    misclassified_filenames = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for pred, true, path in zip(preds, labels, data_loader.dataset.samples):\n",
    "                if pred != true:\n",
    "                    filename = os.path.basename(path[0])  # Extract filename from path\n",
    "                    misclassified_filenames.append(filename)\n",
    "\n",
    "    return misclassified_filenames\n",
    "\n",
    "# Get the list of misclassified filenames\n",
    "misclassified_filenames = list_misclassified_filenames(test_loader, model)\n",
    "\n",
    "# Optionally, print the list\n",
    "for filename in misclassified_filenames:\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(misclassified_filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for filename in misclassified_filenames:\n",
    "    # Split the filename using '-' as a delimiter\n",
    "    parts = filename.split('-')\n",
    "    \n",
    "    # Extract the first part of the split (i.e., the number) and convert it to an integer\n",
    "    first_number = int(parts[1])\n",
    "    \n",
    "    # Check if the first number is greater than 100\n",
    "    if first_number > 100:\n",
    "        count += 1\n",
    "\n",
    "print(\"Professional Signatures:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = r'C:\\Mine\\Work\\Uzi\\Signature_Verification\\test\\positive'\n",
    "\n",
    "# Get the list of files in the folder\n",
    "folder_files = os.listdir(folder_path)\n",
    "count = 0\n",
    "\n",
    "# Iterate through the misclassified filenames and check if they exist in the folder\n",
    "for filename in misclassified_filenames:\n",
    "    if filename in folder_files:\n",
    "        count += 1\n",
    "\n",
    "print(\"Number of misclassified Originals:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "2ba0da8eb658c85323182434a9e32a5d1f692a3d094e26b51496e7fe1b59ddd0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
