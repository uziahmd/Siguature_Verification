{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3062ef6-2e1a-42d1-a89f-66192050dac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow_addons as tfa\n",
    "import glob, random, os, warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "print('TensorFlow Version ' + tf.__version__)\n",
    "\n",
    "def seed_everything(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "\n",
    "seed_everything()\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d09236-46a4-438b-bcf8-d4c1b82a98e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "batch_size = 16\n",
    "num_channels = 1  # Change this to 1 for grayscale images\n",
    "\n",
    "train_path = r'C:\\Mine\\Work\\Uzi\\Signature_Verification\\train'\n",
    "val_path = r'C:\\Mine\\Work\\Uzi\\Signature_Verification\\validation'\n",
    "test_path = r'C:\\Mine\\Work\\Uzi\\Signature_Verification\\test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3dcb16-1227-43e4-8c36-a15c0a052544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augment(image):\n",
    "    # Randomly flip the image horizontally\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "\n",
    "    # Randomly flip the image vertically\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "\n",
    "    # Random rotation\n",
    "    image = tf.image.rot90(image, k=tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n",
    "\n",
    "    # Adding a random brightness change (adjust the max delta as needed)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "\n",
    "    # Adding a random contrast change (adjust the contrast range as needed)\n",
    "    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
    "    return image\n",
    "\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    samplewise_center=True,\n",
    "    samplewise_std_normalization=False,\n",
    "    validation_split=0.2,\n",
    "    preprocessing_function=data_augment\n",
    ")\n",
    "\n",
    "train_gen = datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='training',\n",
    "    color_mode='grayscale'  # For grayscale images\n",
    ")\n",
    "\n",
    "valid_gen = datagen.flow_from_directory(\n",
    "    val_path,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='validation',\n",
    "    color_mode='grayscale'  # For grayscale images\n",
    ")\n",
    "\n",
    "test_gen = datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=False,\n",
    "    color_mode='grayscale'  # For grayscale images\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b3ee61-1aec-476f-94ce-fa72c91f2604",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "num_epochs = 10\n",
    "\n",
    "patch_size = 16\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "projection_dim = 64\n",
    "num_heads = 4\n",
    "transformer_units = [projection_dim * 2, projection_dim]\n",
    "transformer_layers = 8\n",
    "mlp_head_units = [128, 64]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268b2501-e88d-4ff5-8d47-0148d24b5435",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ec991a-0ca7-4e1d-babf-af55f685b9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = L.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = L.Dropout(dropout_rate)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e22f54e-d675-4954-93c5-f15affb60185",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patches(L.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding='VALID',\n",
    "        )\n",
    "        patches = tf.reshape(patches, [batch_size, -1, self.patch_size * self.patch_size * num_channels])\n",
    "        return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900a1fb7-8d93-497d-a63f-3df5cb0d5b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEncoder(L.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = L.Dense(units=projection_dim)\n",
    "        self.position_embedding = L.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee53ff8-1eba-4caf-b61e-97e228d08363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vision_transformer():\n",
    "    inputs = L.Input(shape=(image_size, image_size, num_channels))\n",
    "    \n",
    "    patches = Patches(patch_size)(inputs)\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    for _ in range(transformer_layers):\n",
    "        x1 = L.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        attention_output = L.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        x2 = L.Add()([attention_output, encoded_patches])\n",
    "        x3 = L.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "        encoded_patches = L.Add()([x3, x2])\n",
    "\n",
    "    representation = L.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = L.Flatten()(representation)\n",
    "    representation = L.Dropout(0.5)(representation)\n",
    "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "    logits = L.Dense(1, activation='sigmoid')(features)\n",
    "    \n",
    "    return tf.keras.Model(inputs=inputs, outputs=logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ce8faa-7a39-4b16-a257-e8c0cc2ae7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "decay_steps = train_gen.n // train_gen.batch_size\n",
    "lr_decayed_fn = tf.keras.experimental.CosineDecay(learning_rate, decay_steps)\n",
    "\n",
    "model = vision_transformer()\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr_decayed_fn),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccc3d82-753c-42a0-a084-47253bc7e6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "\n",
    "x = train_gen.next()\n",
    "image = x[0][0]\n",
    "\n",
    "# For grayscale images, you might need to add a color dimension to visualize them correctly\n",
    "if image.shape[-1] == 1:\n",
    "    # Convert grayscale to RGB for visualization\n",
    "    image_vis = np.squeeze(image, axis=-1)\n",
    "    plt.imshow(image_vis, cmap='gray')\n",
    "else:\n",
    "    plt.imshow(image.astype('uint8'))\n",
    "\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Resizing the image to the model's expected input size\n",
    "resized_image = tf.image.resize(\n",
    "    tf.convert_to_tensor([image]), size=(image_size, image_size)\n",
    ")\n",
    "\n",
    "# Generate patches\n",
    "patches = Patches(patch_size)(resized_image)\n",
    "print(f'Image size: {image_size} X {image_size}')\n",
    "print(f'Patch size: {patch_size} X {patch_size}')\n",
    "print(f'Patches per image: {patches.shape[1]}')\n",
    "print(f'Elements per patch: {patches.shape[-1]}')\n",
    "\n",
    "# Visualize the patches\n",
    "n = int(np.sqrt(patches.shape[1]))\n",
    "plt.figure(figsize=(4, 4))\n",
    "\n",
    "for i, patch in enumerate(patches[0]):\n",
    "    ax = plt.subplot(n, n, i + 1)\n",
    "    # Reshape each patch to its original size and visualize\n",
    "    patch_img = tf.reshape(patch, (patch_size, patch_size, num_channels))\n",
    "    \n",
    "    if num_channels == 1:\n",
    "        plt.imshow(np.squeeze(patch_img.numpy(), axis=-1), cmap='gray')\n",
    "    else:\n",
    "        plt.imshow(patch_img.numpy().astype('uint8'))\n",
    "\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c27690-a195-4d87-bacc-16b27c186469",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    min_delta=1e-3,\n",
    "    patience=10,\n",
    "    mode='max',\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "checkpointer = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='./model.hdf5',\n",
    "    monitor='val_accuracy', \n",
    "    verbose=1, \n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "callbacks = [earlystopping, checkpointer]\n",
    "\n",
    "model.fit(\n",
    "    train_gen,\n",
    "    validation_data=valid_gen,\n",
    "    epochs=num_epochs,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca032e49-3ad0-4f06-8229-3bf2cc74a574",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "\n",
    "x = train_gen.next()\n",
    "image = x[0][0]\n",
    "\n",
    "# Display the first image in the batch\n",
    "if image.shape[-1] == 1:\n",
    "    # For grayscale images\n",
    "    plt.imshow(np.squeeze(image, axis=-1), cmap='gray')\n",
    "else:\n",
    "    plt.imshow(image.astype('uint8'))\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Generate patches\n",
    "patches = Patches(patch_size)(tf.convert_to_tensor([image]))\n",
    "\n",
    "# Calculate the number of patches and patch dimensions\n",
    "num_patches = patches.shape[1]\n",
    "patch_dim = patches.shape[-1]\n",
    "\n",
    "print(f'Image size: {image_size} X {image_size}')\n",
    "print(f'Patch size: {patch_size} X {patch_size}')\n",
    "print(f'Patches per image: {num_patches}')\n",
    "print(f'Elements per patch: {patch_dim}')\n",
    "\n",
    "# Visualize the patches\n",
    "n = int(np.sqrt(num_patches))\n",
    "plt.figure(figsize=(4, 4))\n",
    "\n",
    "for i in range(num_patches):\n",
    "    ax = plt.subplot(n, n, i + 1)\n",
    "    patch = patches[0, i]\n",
    "    \n",
    "    # Reshape the patch\n",
    "    patch_img = tf.reshape(patch, (patch_size, patch_size, num_channels))\n",
    "    \n",
    "    if num_channels == 1:\n",
    "        plt.imshow(np.squeeze(patch_img.numpy(), axis=-1), cmap='gray')\n",
    "    else:\n",
    "        plt.imshow(patch_img.numpy().astype('uint8'))\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fb02d9-7581-41ab-907b-fbf9314ad11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = './model_saved'\n",
    "model.save(model_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a79e7ab-dff3-41c5-8836-c3d9eda22178",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model_directory = './model_saved'\n",
    "loaded_model = load_model(model_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ecd7ea-2b96-43df-b0c7-f8831fb5e701",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_gen:\n",
    "    for x in i:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7455b5a2-5050-4e4f-a700-3acd00dda586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = loaded_model.evaluate(test_gen)\n",
    "print(f\"Loss on the test set: {loss}\")\n",
    "print(f\"Accuracy on the test set: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a98830-ff25-46db-91a5-a095b616700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_curve\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def calculate_metrics(labels, scores, far_target=1e-3):\n",
    "    labels = np.array(labels)\n",
    "    scores = np.array(scores).flatten()  # Flattening the array if it's 2D with a single column\n",
    "\n",
    "    # Accuracy\n",
    "    predictions = (scores > 0.5).astype(int)\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "\n",
    "    # Calculate ROC Curve and EER\n",
    "    fpr, tpr, thresholds = roc_curve(labels, scores)\n",
    "    eer = brentq(lambda x: 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n",
    "\n",
    "    # Find TAR at specified FAR\n",
    "    far_index = np.where(fpr <= far_target)[0][-1]\n",
    "    tar_at_far = tpr[far_index]\n",
    "\n",
    "    return accuracy, eer, tar_at_far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebd2684-9f37-4797-99a8-53a017acacf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Generate Predictions and Labels\n",
    "test_labels = [] # Initialize an empty list for true labels\n",
    "test_scores = [] # Initialize an empty list for predicted scores\n",
    "\n",
    "for batch in test_gen:\n",
    "    images, labels = batch\n",
    "    scores = loaded_model.predict(images)  # Predict probabilities\n",
    "    test_scores.extend(scores)\n",
    "    test_labels.extend(labels)\n",
    "\n",
    "    if len(test_labels) >= test_gen.n:\n",
    "        break\n",
    "\n",
    "# Step 2: Prepare the Data\n",
    "# Ensure the labels and scores are in the correct format\n",
    "test_labels = np.array(test_labels)\n",
    "test_scores = np.array(test_scores)\n",
    "\n",
    "# Step 3: Calculate the Metrics\n",
    "accuracy, eer, tar_at_far = calculate_metrics(test_labels, test_scores)\n",
    "\n",
    "# Print the Results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"EER: {eer}\")\n",
    "print(f\"TAR at FAR={1e-3}: {tar_at_far}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a48c82f-0d3c-4ecc-b627-6b41130de47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the Results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"EER: {eer}\")\n",
    "print(f\"TAR at FAR={1e-3}: {tar_at_far}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152db1fb-9c0b-416d-80d1-3e549b191aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_misclassified_filenames(data_generator, model):\n",
    "    misclassified_filenames = []\n",
    "    # Get total number of samples\n",
    "    total_samples = data_generator.n\n",
    "    batch_size = data_generator.batch_size\n",
    "\n",
    "    # Iterate over all batches\n",
    "    for i in range((total_samples // batch_size) + 1):\n",
    "        # Load batch\n",
    "        batch = data_generator.next()\n",
    "        images, labels = batch\n",
    "\n",
    "        # Get predictions\n",
    "        preds = model.predict(images)\n",
    "        preds = (preds > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
    "\n",
    "        # Calculate number of images in the current batch (it might be smaller than batch_size for the last batch)\n",
    "        current_batch_size = len(images)\n",
    "        \n",
    "        for j in range(current_batch_size):\n",
    "            true_label = labels[j]\n",
    "            pred_label = preds[j]\n",
    "\n",
    "            # Calculate the correct index in the filepaths list\n",
    "            current_index = i * batch_size + j\n",
    "            if current_index < total_samples:\n",
    "                if pred_label != true_label:\n",
    "                    # Get the filename from the data generator's filepaths\n",
    "                    filename = os.path.basename(data_generator.filepaths[current_index])\n",
    "                    misclassified_filenames.append(filename)\n",
    "\n",
    "    return misclassified_filenames\n",
    "\n",
    "# Get the list of misclassified filenames\n",
    "misclassified_filenames = list_misclassified_filenames(test_gen, loaded_model)\n",
    "\n",
    "# Optionally, print the list\n",
    "for filename in misclassified_filenames:\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f9f0b0-9706-4665-92b9-6d6234ee61b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(misclassified_filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147b8eaf-b6ff-4b2b-827a-db17c46f045a",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for filename in misclassified_filenames:\n",
    "    # Split the filename using '-' as a delimiter\n",
    "    parts = filename.split('-')\n",
    "    \n",
    "    # Extract the first part of the split (i.e., the number) and convert it to an integer\n",
    "    first_number = int(parts[1])\n",
    "    \n",
    "    # Check if the first number is greater than 100\n",
    "    if first_number > 100:\n",
    "        count += 1\n",
    "\n",
    "print(\"Professional Signatures:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26d83dd-dc01-4a4d-93fa-4046d5cc02a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def visualize_misclassified_samples_with_filenames(data_generator, model, num_images=10, title='Misclassified Samples'):\n",
    "    misclassified_images, predictions, true_labels, filenames = [], [], [], []\n",
    "    total_samples = data_generator.n\n",
    "    batch_size = data_generator.batch_size\n",
    "\n",
    "    # Iterate over all batches\n",
    "    for i in range((total_samples // batch_size) + 1):\n",
    "        # Load batch\n",
    "        batch = data_generator.next()\n",
    "        images, labels = batch\n",
    "\n",
    "        # Get predictions\n",
    "        preds = model.predict(images)\n",
    "        preds = (preds > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
    "\n",
    "        # Calculate number of images in the current batch\n",
    "        current_batch_size = len(images)\n",
    "        \n",
    "        for j in range(current_batch_size):\n",
    "            true_label = labels[j]\n",
    "            pred_label = preds[j]\n",
    "\n",
    "            # Calculate the correct index in the filepaths list\n",
    "            current_index = i * batch_size + j\n",
    "            if current_index < total_samples and pred_label != true_label:\n",
    "                misclassified_images.append(images[j])\n",
    "                predictions.append(pred_label[0])\n",
    "                true_labels.append(true_label)\n",
    "                filenames.append(os.path.basename(data_generator.filepaths[current_index]))\n",
    "\n",
    "                if len(misclassified_images) == num_images:\n",
    "                    break\n",
    "        if len(misclassified_images) == num_images:\n",
    "            break\n",
    "\n",
    "    # Plotting\n",
    "    fig, axes = plt.subplots(2, num_images // 2, figsize=(15, 5))\n",
    "    fig.suptitle(title)\n",
    "    axes = axes.flatten()\n",
    "    for i, (img, pred, true, fname) in enumerate(zip(misclassified_images, predictions, true_labels, filenames)):\n",
    "        if img.shape[-1] == 1:\n",
    "            # For grayscale images\n",
    "            img = np.squeeze(img, axis=-1)\n",
    "            cmap = 'gray'\n",
    "        else:\n",
    "            # For RGB images\n",
    "            cmap = None\n",
    "        axes[i].imshow(img, cmap=cmap)\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title(f'File: {fname}\\nPred: {pred}, True: {true}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to visualize misclassified samples with filenames\n",
    "visualize_misclassified_samples_with_filenames(test_gen, loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad53be0-9e6d-481f-bd02-0a456bd4f105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def visualize_misclassified_samples_with_filenames(data_generator, model, num_images=10, title='Misclassified Samples'):\n",
    "    misclassified_images, predictions, true_labels, filenames = [], [], [], []\n",
    "    total_samples = data_generator.n\n",
    "    batch_size = data_generator.batch_size\n",
    "\n",
    "    # Iterate over all batches\n",
    "    for i in range((total_samples // batch_size) + 1):\n",
    "        # Load batch\n",
    "        batch = data_generator.next()\n",
    "        images, labels = batch\n",
    "\n",
    "        # Get predictions\n",
    "        preds = model.predict(images)\n",
    "        preds = (preds > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
    "\n",
    "        # Calculate number of images in the current batch\n",
    "        current_batch_size = len(images)\n",
    "        \n",
    "        for j in range(current_batch_size):\n",
    "            true_label = labels[j]\n",
    "            pred_label = preds[j]\n",
    "\n",
    "            # Calculate the correct index in the filepaths list\n",
    "            current_index = i * batch_size + j\n",
    "            if current_index < total_samples and pred_label != true_label:\n",
    "                misclassified_images.append(images[j])\n",
    "                predictions.append(pred_label[0])\n",
    "                true_labels.append(true_label)\n",
    "                filenames.append(os.path.basename(data_generator.filepaths[current_index]))\n",
    "\n",
    "                if len(misclassified_images) == num_images:\n",
    "                    break\n",
    "        if len(misclassified_images) == num_images:\n",
    "            break\n",
    "\n",
    "    # Plotting\n",
    "    fig, axes = plt.subplots(2, num_images // 2, figsize=(15, 5))\n",
    "    fig.suptitle(title)\n",
    "    axes = axes.flatten()\n",
    "    for i, (img, pred, true, fname) in enumerate(zip(misclassified_images, predictions, true_labels, filenames)):\n",
    "        if img.shape[-1] == 1:\n",
    "            # For grayscale images\n",
    "            img = np.squeeze(img, axis=-1)\n",
    "            cmap = 'gray'\n",
    "        else:\n",
    "            # For RGB images\n",
    "            cmap = None\n",
    "        axes[i].imshow(img, cmap=cmap)\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title(f'File: {fname}\\nPred: {pred}, True: {true}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to visualize misclassified samples with filenames\n",
    "visualize_misclassified_samples_with_filenames(test_gen, loaded_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
