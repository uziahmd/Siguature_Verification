{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\faiza\\.conda\\envs\\sci_data\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import timm\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm  \n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations for the input data\n",
    "# Adjust the size for InceptionResNet's input requirements\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),  # Adjusting to InceptionResNet size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and transform datasets\n",
    "train_data = ImageFolder(root=r'C:\\Mine\\Work\\Uzi\\Signature_Verification\\train', transform=transform)\n",
    "val_data = ImageFolder(root=r'C:\\Mine\\Work\\Uzi\\Signature_Verification\\validation', transform=transform)\n",
    "test_data = ImageFolder(root=r'C:\\Mine\\Work\\Uzi\\Signature_Verification\\test', transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super(BasicConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return F.relu(x, inplace=True)\n",
    "\n",
    "class InceptionResnetA(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(InceptionResnetA, self).__init__()\n",
    "        self.branch1x1 = BasicConv2d(in_channels, 32, kernel_size=1)\n",
    "\n",
    "        self.branch5x5_1 = BasicConv2d(in_channels, 32, kernel_size=1)\n",
    "        self.branch5x5_2 = BasicConv2d(32, 32, kernel_size=5, padding=2)\n",
    "\n",
    "        self.branch3x3dbl_1 = BasicConv2d(in_channels, 32, kernel_size=1)\n",
    "        self.branch3x3dbl_2 = BasicConv2d(32, 48, kernel_size=3, padding=1)\n",
    "        self.branch3x3dbl_3 = BasicConv2d(48, 64, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv2d = nn.Conv2d(128, in_channels, kernel_size=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch1x1 = self.branch1x1(x)\n",
    "\n",
    "        branch5x5 = self.branch5x5_1(x)\n",
    "        branch5x5 = self.branch5x5_2(branch5x5)\n",
    "\n",
    "        branch3x3dbl = self.branch3x3dbl_1(x)\n",
    "        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n",
    "        branch3x3dbl = self.branch3x3dbl_3(branch3x3dbl)\n",
    "\n",
    "        outputs = [branch1x1, branch5x5, branch3x3dbl]\n",
    "        outputs = torch.cat(outputs, 1)\n",
    "        outputs = self.conv2d(outputs)\n",
    "        outputs = self.relu(outputs + x)\n",
    "        return outputs\n",
    "\n",
    "# Similarly, define InceptionResnetB and InceptionResnetC for other blocks\n",
    "\n",
    "class InceptionResNetV1(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(InceptionResNetV1, self).__init__()\n",
    "        # Define the stem of the network\n",
    "        self.stem = nn.Sequential(\n",
    "            BasicConv2d(3, 32, kernel_size=3, stride=2),\n",
    "            BasicConv2d(32, 32, kernel_size=3),\n",
    "            BasicConv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "            BasicConv2d(64, 80, kernel_size=1),\n",
    "            BasicConv2d(80, 192, kernel_size=3),\n",
    "            nn.MaxPool2d(3, stride=2)\n",
    "        )\n",
    "\n",
    "        # Define the Inception-ResNet blocks\n",
    "        self.inception_resnet_a = InceptionResnetA(192)\n",
    "        # Add more blocks here...\n",
    "\n",
    "        # Define the classifier\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(192, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.inception_resnet_a(x)\n",
    "        # Pass through additional blocks...\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Create the model instance\n",
    "model = InceptionResNetV1(num_classes=len(train_data.classes))\n",
    "\n",
    "\n",
    "class InceptionResnetB(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(InceptionResnetB, self).__init__()\n",
    "        self.branch7x7 = nn.Sequential(\n",
    "            BasicConv2d(in_channels, 128, kernel_size=1),\n",
    "            BasicConv2d(128, 128, kernel_size=(1, 7), padding=(0, 3)),\n",
    "            BasicConv2d(128, 192, kernel_size=(7, 1), padding=(3, 0))\n",
    "        )\n",
    "\n",
    "        self.conv2d = nn.Conv2d(192, in_channels, kernel_size=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch7x7 = self.branch7x7(x)\n",
    "\n",
    "        outputs = self.conv2d(branch7x7)\n",
    "        outputs = self.relu(outputs + x)\n",
    "        return outputs\n",
    "\n",
    "class InceptionResnetC(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(InceptionResnetC, self).__init__()\n",
    "        self.branch3x3 = nn.Sequential(\n",
    "            BasicConv2d(in_channels, 192, kernel_size=1),\n",
    "            BasicConv2d(192, 224, kernel_size=(1, 3), padding=(0, 1)),\n",
    "            BasicConv2d(224, 256, kernel_size=(3, 1), padding=(1, 0))\n",
    "        )\n",
    "\n",
    "        self.conv2d = nn.Conv2d(256, in_channels, kernel_size=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch3x3 = self.branch3x3(x)\n",
    "\n",
    "        outputs = self.conv2d(branch3x3)\n",
    "        outputs = self.relu(outputs + x)\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionResNetV1(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(InceptionResNetV1, self).__init__()\n",
    "        # Define the stem of the network\n",
    "        self.stem = nn.Sequential(\n",
    "            BasicConv2d(3, 32, kernel_size=3, stride=2),\n",
    "            BasicConv2d(32, 32, kernel_size=3),\n",
    "            BasicConv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "            BasicConv2d(64, 80, kernel_size=1),\n",
    "            BasicConv2d(80, 192, kernel_size=3),\n",
    "            nn.MaxPool2d(3, stride=2)\n",
    "        )\n",
    "\n",
    "        # Define the Inception-ResNet blocks\n",
    "        # Adjust the number of blocks based on your requirements\n",
    "        self.inception_resnet_a = nn.Sequential(*[InceptionResnetA(192) for _ in range(5)])\n",
    "        self.inception_resnet_b = nn.Sequential(*[InceptionResnetB(192) for _ in range(10)])\n",
    "        self.inception_resnet_c = nn.Sequential(*[InceptionResnetC(192) for _ in range(5)])\n",
    "\n",
    "        # Define the classifier\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(192, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.inception_resnet_a(x)\n",
    "        x = self.inception_resnet_b(x)\n",
    "        x = self.inception_resnet_c(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Create the model instance\n",
    "model = InceptionResNetV1(num_classes=len(train_data.classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 225/225 [01:44<00:00,  2.16batch/s, loss=0.0513]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.46823190251986185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:09<00:00,  5.12batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the validation images: 79.8828125%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 225/225 [01:39<00:00,  2.26batch/s, loss=0.00323]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Loss: 0.4096349996814711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:08<00:00,  5.40batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the validation images: 61.1328125%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 225/225 [01:38<00:00,  2.29batch/s, loss=3.7]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Loss: 0.4047571271657944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:08<00:00,  5.41batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the validation images: 80.92447916666667%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 225/225 [01:38<00:00,  2.28batch/s, loss=0.018]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Loss: 0.38702853746712207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:08<00:00,  5.43batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the validation images: 82.87760416666667%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 225/225 [01:38<00:00,  2.29batch/s, loss=4.53] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Loss: 0.38268827733066346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:08<00:00,  5.42batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the validation images: 83.85416666666667%\n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 5  # Set the number of epochs\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
    "        for images, labels in tepoch:\n",
    "            tepoch.set_description(f\"Epoch {epoch+1}\")\n",
    "\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            tepoch.set_postfix(loss=loss.item())\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader)}')\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad(), tqdm(val_loader, unit=\"batch\") as vepoch:\n",
    "        for images, labels in vepoch:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        vepoch.set_postfix(validation_accuracy=100 * correct / total)\n",
    "\n",
    "    print(f'Accuracy of the model on the validation images: {100 * correct / total}%')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, '5epoch_inceptionresnetv2.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 48/48 [00:09<00:00,  5.10batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Accuracy: 0.8385, False Accepted: 108, False Rejected: 140, Total Forged: 1240, Total Genuine: 296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 49/49 [00:09<00:00,  5.06batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Accuracy: 0.8562, False Accepted: 85, False Rejected: 136, Total Forged: 1249, Total Genuine: 288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    all_scores = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(data_loader, desc='Evaluating', unit='batch'):\n",
    "            inputs = inputs.to(device)  # Ensure data is on the correct device\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            probabilities = F.softmax(outputs, dim=1)[:, 1]  # Assuming binary classification\n",
    "            all_scores.extend(probabilities.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Convert scores to binary predictions using a threshold (e.g., 0.5)\n",
    "    threshold = 0.5\n",
    "    predictions = [1 if score > threshold else 0 for score in all_scores]\n",
    "\n",
    "    # Confusion Matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(all_labels, predictions).ravel()\n",
    "\n",
    "    # Calculate Accuracy\n",
    "    acc = accuracy_score(all_labels, predictions)\n",
    "\n",
    "    # Additional Calculations\n",
    "    num_false_accepted = fp\n",
    "    num_false_rejected = fn\n",
    "    total_num_forged = fp + tn\n",
    "    total_num_genuine = fn + tp\n",
    "\n",
    "    return acc, num_false_accepted, num_false_rejected, total_num_forged, total_num_genuine\n",
    "\n",
    "# Example usage\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)  # Replace 'model' with your InceptionResNetV2 model\n",
    "\n",
    "# Assuming val_loader and test_loader are defined\n",
    "val_acc, val_fa, val_fr, val_total_forged, val_total_genuine = evaluate_model(model, val_loader)\n",
    "print(f'Validation: Accuracy: {val_acc:.4f}, False Accepted: {val_fa}, False Rejected: {val_fr}, Total Forged: {val_total_forged}, Total Genuine: {val_total_genuine}')\n",
    "\n",
    "test_acc, test_fa, test_fr, test_total_forged, test_total_genuine = evaluate_model(model, test_loader)\n",
    "print(f'Test: Accuracy: {test_acc:.4f}, False Accepted: {test_fa}, False Rejected: {test_fr}, Total Forged: {test_total_forged}, Total Genuine: {test_total_genuine}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m     16\u001b[0m classes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mForged\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGenuine\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Change as per your class names\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m plot_confusion_matrix(\u001b[43mall_labels\u001b[49m, predictions, classes)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'all_labels' is not defined"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(true_labels, predictions, classes):\n",
    "    conf_mat = confusion_matrix(true_labels, predictions)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=classes, yticklabels=classes)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "classes = ['Forged', 'Genuine']  # Change as per your class names\n",
    "plot_confusion_matrix(all_labels, predictions, classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
