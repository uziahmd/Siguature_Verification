{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import timm\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm  # Import tqdm\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations for the input data\n",
    "# Adjust the size for InceptionResNet's input requirements\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),  # Adjusting to InceptionResNet size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and transform datasets\n",
    "train_data = ImageFolder(root='W:/OneDrive - kaist.ac.kr/KAIST/Courses/5th Sem/CS470/New/train', transform=transform)\n",
    "val_data = ImageFolder(root='W:/OneDrive - kaist.ac.kr/KAIST/Courses/5th Sem/CS470/New/validation', transform=transform)\n",
    "test_data = ImageFolder(root='W:/OneDrive - kaist.ac.kr/KAIST/Courses/5th Sem/CS470/New/test', transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super(BasicConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return F.relu(x, inplace=True)\n",
    "\n",
    "class InceptionResnetA(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(InceptionResnetA, self).__init__()\n",
    "        self.branch1x1 = BasicConv2d(in_channels, 32, kernel_size=1)\n",
    "\n",
    "        self.branch5x5_1 = BasicConv2d(in_channels, 32, kernel_size=1)\n",
    "        self.branch5x5_2 = BasicConv2d(32, 32, kernel_size=5, padding=2)\n",
    "\n",
    "        self.branch3x3dbl_1 = BasicConv2d(in_channels, 32, kernel_size=1)\n",
    "        self.branch3x3dbl_2 = BasicConv2d(32, 48, kernel_size=3, padding=1)\n",
    "        self.branch3x3dbl_3 = BasicConv2d(48, 64, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv2d = nn.Conv2d(128, in_channels, kernel_size=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch1x1 = self.branch1x1(x)\n",
    "\n",
    "        branch5x5 = self.branch5x5_1(x)\n",
    "        branch5x5 = self.branch5x5_2(branch5x5)\n",
    "\n",
    "        branch3x3dbl = self.branch3x3dbl_1(x)\n",
    "        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n",
    "        branch3x3dbl = self.branch3x3dbl_3(branch3x3dbl)\n",
    "\n",
    "        outputs = [branch1x1, branch5x5, branch3x3dbl]\n",
    "        outputs = torch.cat(outputs, 1)\n",
    "        outputs = self.conv2d(outputs)\n",
    "        outputs = self.relu(outputs + x)\n",
    "        return outputs\n",
    "\n",
    "# Similarly, define InceptionResnetB and InceptionResnetC for other blocks\n",
    "\n",
    "class InceptionResNetV1(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(InceptionResNetV1, self).__init__()\n",
    "        # Define the stem of the network\n",
    "        self.stem = nn.Sequential(\n",
    "            BasicConv2d(3, 32, kernel_size=3, stride=2),\n",
    "            BasicConv2d(32, 32, kernel_size=3),\n",
    "            BasicConv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "            BasicConv2d(64, 80, kernel_size=1),\n",
    "            BasicConv2d(80, 192, kernel_size=3),\n",
    "            nn.MaxPool2d(3, stride=2)\n",
    "        )\n",
    "\n",
    "        # Define the Inception-ResNet blocks\n",
    "        self.inception_resnet_a = InceptionResnetA(192)\n",
    "        # Add more blocks here...\n",
    "\n",
    "        # Define the classifier\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(192, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.inception_resnet_a(x)\n",
    "        # Pass through additional blocks...\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Create the model instance\n",
    "model = InceptionResNetV1(num_classes=len(train_data.classes))\n",
    "\n",
    "\n",
    "class InceptionResnetB(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(InceptionResnetB, self).__init__()\n",
    "        self.branch7x7 = nn.Sequential(\n",
    "            BasicConv2d(in_channels, 128, kernel_size=1),\n",
    "            BasicConv2d(128, 128, kernel_size=(1, 7), padding=(0, 3)),\n",
    "            BasicConv2d(128, 192, kernel_size=(7, 1), padding=(3, 0))\n",
    "        )\n",
    "\n",
    "        self.conv2d = nn.Conv2d(192, in_channels, kernel_size=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch7x7 = self.branch7x7(x)\n",
    "\n",
    "        outputs = self.conv2d(branch7x7)\n",
    "        outputs = self.relu(outputs + x)\n",
    "        return outputs\n",
    "\n",
    "class InceptionResnetC(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(InceptionResnetC, self).__init__()\n",
    "        self.branch3x3 = nn.Sequential(\n",
    "            BasicConv2d(in_channels, 192, kernel_size=1),\n",
    "            BasicConv2d(192, 224, kernel_size=(1, 3), padding=(0, 1)),\n",
    "            BasicConv2d(224, 256, kernel_size=(3, 1), padding=(1, 0))\n",
    "        )\n",
    "\n",
    "        self.conv2d = nn.Conv2d(256, in_channels, kernel_size=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch3x3 = self.branch3x3(x)\n",
    "\n",
    "        outputs = self.conv2d(branch3x3)\n",
    "        outputs = self.relu(outputs + x)\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionResNetV1(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(InceptionResNetV1, self).__init__()\n",
    "        # Define the stem of the network\n",
    "        self.stem = nn.Sequential(\n",
    "            BasicConv2d(3, 32, kernel_size=3, stride=2),\n",
    "            BasicConv2d(32, 32, kernel_size=3),\n",
    "            BasicConv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "            BasicConv2d(64, 80, kernel_size=1),\n",
    "            BasicConv2d(80, 192, kernel_size=3),\n",
    "            nn.MaxPool2d(3, stride=2)\n",
    "        )\n",
    "\n",
    "        # Define the Inception-ResNet blocks\n",
    "        # Adjust the number of blocks based on your requirements\n",
    "        self.inception_resnet_a = nn.Sequential(*[InceptionResnetA(192) for _ in range(5)])\n",
    "        self.inception_resnet_b = nn.Sequential(*[InceptionResnetB(192) for _ in range(10)])\n",
    "        self.inception_resnet_c = nn.Sequential(*[InceptionResnetC(192) for _ in range(5)])\n",
    "\n",
    "        # Define the classifier\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(192, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.inception_resnet_a(x)\n",
    "        x = self.inception_resnet_b(x)\n",
    "        x = self.inception_resnet_c(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Create the model instance\n",
    "model = InceptionResNetV1(num_classes=len(train_data.classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping\n",
    "early_stopping = EarlyStopping(patience=3, min_delta=0.01)\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 5  # Set the number of epochs\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
    "        for images, labels in tepoch:\n",
    "            tepoch.set_description(f\"Epoch {epoch+1}\")\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            tepoch.set_postfix(loss=loss.item())\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader)}')\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad(), tqdm(val_loader, unit=\"batch\") as vepoch:\n",
    "        for images, labels in vepoch:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    print(f'Validation Loss: {val_loss}, Accuracy: {100 * correct / total}%')\n",
    "\n",
    "    # Check early stopping condition\n",
    "    early_stopping(val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, '5epoch_inceptionresnetv2.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def calculate_eer_and_tar(y_true, y_scores, far_target=0.01):\n",
    "    # Compute the ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "    \n",
    "    # Find the EER\n",
    "    eer_threshold = thresholds[np.nanargmin(np.abs(fpr - (1 - tpr)))]\n",
    "    eer = fpr[np.nanargmin(np.abs(fpr - (1 - tpr)))]\n",
    "    \n",
    "    # Find the TAR at a specific FAR\n",
    "    tar_at_far = tpr[np.nanargmin(np.abs(fpr - far_target))]\n",
    "\n",
    "    return eer, tar_at_far, eer_threshold\n",
    "\n",
    "# Use this function after obtaining y_scores (model probabilities) and y_true (actual labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing loop\n",
    "model.eval()\n",
    "y_scores = []\n",
    "y_true = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        probabilities = F.softmax(outputs, dim=1)[:, 1]  # Probabilities for the positive class\n",
    "        y_scores.extend(probabilities.cpu().numpy())\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate EER and TAR\n",
    "eer, tar_at_far, _ = calculate_eer_and_tar(y_true, y_scores)\n",
    "print(f\"EER: {eer}, TAR at FAR={far_target}: {tar_at_far}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
